{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOVoai789AYw3j1mF6P4JxO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/1zulkifel/AI_Q_3/blob/main/NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvIfG0Yutz-e"
      },
      "source": [
        "<font color = 'red'>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUx2i0Wlt5Ki"
      },
      "source": [
        "#<font color='red'> Word-level one-hot encoding (toy example) </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-xhxCgpuAwQ"
      },
      "source": [
        "import numpy as np\n",
        "samples = ['The cat sat on the mat.', 'The dog ate my homework.', \"پاکستان زندہ باد\"]\n",
        "token_index = {}\n",
        "for sample in samples:\n",
        "    for word in sample.split():\n",
        "        if word not in token_index:\n",
        "            token_index[word] = len(token_index) + 1\n",
        "            \n",
        "max_length = 10\n",
        "results = np.zeros(shape=(len(samples),\n",
        "                          max_length,\n",
        "                          max(token_index.values()) + 1))\n",
        "for i, sample in enumerate(samples):\n",
        "    for j, word in list(enumerate(sample.split()))[:max_length]:\n",
        "        index = token_index.get(word)\n",
        "        results[i, j, index] = 1."
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qne1wbUMuYJl",
        "outputId": "62ccb8bd-0001-4c2d-e693-9cff99ad4b84"
      },
      "source": [
        "token_index"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'The': 1,\n",
              " 'ate': 8,\n",
              " 'cat': 2,\n",
              " 'dog': 7,\n",
              " 'homework.': 10,\n",
              " 'mat.': 6,\n",
              " 'my': 9,\n",
              " 'on': 4,\n",
              " 'sat': 3,\n",
              " 'the': 5,\n",
              " 'باد': 13,\n",
              " 'زندہ': 12,\n",
              " 'پاکستان': 11}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THZRqX-Aubf3",
        "outputId": "2c67888f-9fb7-4027-d42d-af7f8f8c9597"
      },
      "source": [
        "\n",
        "results\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
              "\n",
              "       [[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
              "\n",
              "       [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bFgTmyGuf9H"
      },
      "source": [
        "#<font color='red'> </font>"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5z3_NeBsvMVH"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QrotjnGcupGJ"
      },
      "source": [
        "# <font color='red'>  Character-level one-hot encoding (toy example) </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9JE_1oru8Pa"
      },
      "source": [
        "import string\n",
        "samples = ['The cat sat on the mat.', 'The dog ate my homework.']\n",
        "characters = string.printable\n",
        "token_index = dict(zip(range(1, len(characters) + 1), characters))\n",
        "max_length = 50\n",
        "results = np.zeros((len(samples), max_length, max(token_index.keys()) + 1))\n",
        "for i, sample in enumerate(samples):\n",
        "    for j, character in enumerate(sample):\n",
        "        index = token_index.get(character)\n",
        "        results[i, j, index] = 1."
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHBRJTmKvFfH",
        "outputId": "185e224c-e94f-47ac-d25a-1c4a25745a4d"
      },
      "source": [
        "print(len(token_index))\n",
        "token_index"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1: '0',\n",
              " 2: '1',\n",
              " 3: '2',\n",
              " 4: '3',\n",
              " 5: '4',\n",
              " 6: '5',\n",
              " 7: '6',\n",
              " 8: '7',\n",
              " 9: '8',\n",
              " 10: '9',\n",
              " 11: 'a',\n",
              " 12: 'b',\n",
              " 13: 'c',\n",
              " 14: 'd',\n",
              " 15: 'e',\n",
              " 16: 'f',\n",
              " 17: 'g',\n",
              " 18: 'h',\n",
              " 19: 'i',\n",
              " 20: 'j',\n",
              " 21: 'k',\n",
              " 22: 'l',\n",
              " 23: 'm',\n",
              " 24: 'n',\n",
              " 25: 'o',\n",
              " 26: 'p',\n",
              " 27: 'q',\n",
              " 28: 'r',\n",
              " 29: 's',\n",
              " 30: 't',\n",
              " 31: 'u',\n",
              " 32: 'v',\n",
              " 33: 'w',\n",
              " 34: 'x',\n",
              " 35: 'y',\n",
              " 36: 'z',\n",
              " 37: 'A',\n",
              " 38: 'B',\n",
              " 39: 'C',\n",
              " 40: 'D',\n",
              " 41: 'E',\n",
              " 42: 'F',\n",
              " 43: 'G',\n",
              " 44: 'H',\n",
              " 45: 'I',\n",
              " 46: 'J',\n",
              " 47: 'K',\n",
              " 48: 'L',\n",
              " 49: 'M',\n",
              " 50: 'N',\n",
              " 51: 'O',\n",
              " 52: 'P',\n",
              " 53: 'Q',\n",
              " 54: 'R',\n",
              " 55: 'S',\n",
              " 56: 'T',\n",
              " 57: 'U',\n",
              " 58: 'V',\n",
              " 59: 'W',\n",
              " 60: 'X',\n",
              " 61: 'Y',\n",
              " 62: 'Z',\n",
              " 63: '!',\n",
              " 64: '\"',\n",
              " 65: '#',\n",
              " 66: '$',\n",
              " 67: '%',\n",
              " 68: '&',\n",
              " 69: \"'\",\n",
              " 70: '(',\n",
              " 71: ')',\n",
              " 72: '*',\n",
              " 73: '+',\n",
              " 74: ',',\n",
              " 75: '-',\n",
              " 76: '.',\n",
              " 77: '/',\n",
              " 78: ':',\n",
              " 79: ';',\n",
              " 80: '<',\n",
              " 81: '=',\n",
              " 82: '>',\n",
              " 83: '?',\n",
              " 84: '@',\n",
              " 85: '[',\n",
              " 86: '\\\\',\n",
              " 87: ']',\n",
              " 88: '^',\n",
              " 89: '_',\n",
              " 90: '`',\n",
              " 91: '{',\n",
              " 92: '|',\n",
              " 93: '}',\n",
              " 94: '~',\n",
              " 95: ' ',\n",
              " 96: '\\t',\n",
              " 97: '\\n',\n",
              " 98: '\\r',\n",
              " 99: '\\x0b',\n",
              " 100: '\\x0c'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGpDnyiKvf0J",
        "outputId": "fdeb3487-9257-4ba1-eb71-1c6475093292"
      },
      "source": [
        "results"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[1., 1., 1., ..., 1., 1., 1.],\n",
              "        [1., 1., 1., ..., 1., 1., 1.],\n",
              "        [1., 1., 1., ..., 1., 1., 1.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "       [[1., 1., 1., ..., 1., 1., 1.],\n",
              "        [1., 1., 1., ..., 1., 1., 1.],\n",
              "        [1., 1., 1., ..., 1., 1., 1.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAxGA_jEvgzk",
        "outputId": "0a672ee9-d393-46a3-9122-89590112f9b8"
      },
      "source": [
        "print(len(results[0]))\n",
        "results[0]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 1., 1., ..., 1., 1., 1.],\n",
              "       [1., 1., 1., ..., 1., 1., 1.],\n",
              "       [1., 1., 1., ..., 1., 1., 1.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wol8HdJMvro2"
      },
      "source": [
        "#<font color='red'> Using Keras for word-level one-hot encoding</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-pyziCpvn25",
        "outputId": "309be6e5-9f5b-4d86-864b-a8d9ff0e9dbc"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "samples = ['The cat sat on the mat.', 'The dog ate my homework.']\n",
        "tokenizer = Tokenizer(num_words=1000)\n",
        "tokenizer.fit_on_texts(samples)\n",
        "sequences = tokenizer.texts_to_sequences(samples)\n",
        "one_hot_results = tokenizer.texts_to_matrix(samples, mode='binary')\n",
        "word_index = tokenizer.word_index\n",
        "print('Found %s unique tokens.' % len(word_index))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 9 unique tokens.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ae6uMoowBsW",
        "outputId": "ff0019ec-8b98-4293-ee08-ff073e94da6f"
      },
      "source": [
        "tokenizer.texts_to_matrix(samples)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1., 1., ..., 0., 0., 0.],\n",
              "       [0., 1., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HuaubcM-wMPc",
        "outputId": "96306c15-9bce-42df-b800-fae9b4f87cd0"
      },
      "source": [
        "\n",
        "tokenizer"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras_preprocessing.text.Tokenizer at 0x7f1161408a90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-lCQQpvwPQw",
        "outputId": "f604098b-c85c-408b-b26e-7c87f7cf5ea3"
      },
      "source": [
        "sequences"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 2, 3, 4, 1, 5], [1, 6, 7, 8, 9]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3s8lf5M3wRsR",
        "outputId": "b09380b5-f385-43a8-9ff4-c67d94509257"
      },
      "source": [
        "one_hot_results"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1., 1., ..., 0., 0., 0.],\n",
              "       [0., 1., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ITReNwepwagS",
        "outputId": "0a0b4c16-1a7f-4bc9-9294-e555b10592c2"
      },
      "source": [
        "one_hot_results.shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 1000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYVj4uhewdRY",
        "outputId": "69f2983b-4e35-486d-be8d-a804b47327a4"
      },
      "source": [
        "word_index "
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ate': 7,\n",
              " 'cat': 2,\n",
              " 'dog': 6,\n",
              " 'homework': 9,\n",
              " 'mat': 5,\n",
              " 'my': 8,\n",
              " 'on': 4,\n",
              " 'sat': 3,\n",
              " 'the': 1}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kDDIOhLw720"
      },
      "source": [
        "#<font color='red'> Word-level one-hot encoding with hashing trick (toy example)  </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DVEJuTiw_ZZ"
      },
      "source": [
        "samples = ['The cat sat on the mat.', 'The dog ate my homework.']\n",
        "dimensionality = 1000\n",
        "max_length = 10\n",
        "results = np.zeros((len(samples), max_length, dimensionality))\n",
        "for i, sample in enumerate(samples):\n",
        "    for j, word in list(enumerate(sample.split()))[:max_length]:\n",
        "        index = abs(hash(word)) % dimensionality\n",
        "        results[i, j, index] = 1."
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-07xRa44xGP5",
        "outputId": "8a50f219-d3a7-4fc1-9a72-f7516f82a7f1"
      },
      "source": [
        "results.shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 10, 1000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K7mzn3pAxJfv",
        "outputId": "68fc3996-ffe2-46ca-9bd5-1bd3afcbdc2e"
      },
      "source": [
        "abs(hash('abx'))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1136749758504927533"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CFBeR_mDxQ0b",
        "outputId": "600ffd68-c4fe-469a-e66e-19e61db45c8e"
      },
      "source": [
        "abs(hash('mat')) %max_length"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erGB7v2yxxeX"
      },
      "source": [
        "#<font color='red'>Instantiating an Embedding layer </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wq0iPdO_x0C7",
        "outputId": "a18a5dc2-6f8e-479d-e044-0022f65f9f1e"
      },
      "source": [
        "from tensorflow.keras.layers import Embedding\n",
        "embedding_layer = Embedding(1000, 64)\n",
        "embedding_layer"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.layers.embeddings.Embedding at 0x7f91d8557210>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8g9oXJ5X2VF1"
      },
      "source": [
        "#<font color='red'>Loading the IMDB data for use with an Embedding layer </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "czPrO-u-2Z1a",
        "outputId": "98320b46-1cf3-4f6f-8aa1-465e6c7b6753"
      },
      "source": [
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras import preprocessing\n",
        "max_features = 10000\n",
        "maxlen = 20\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "\n",
        "x_train = preprocessing.sequence.pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = preprocessing.sequence.pad_sequences(x_test, maxlen=maxlen)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:155: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:156: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvH-QMk02pA5"
      },
      "source": [
        "#<font color='red'>Using an Embedding layer and classifier on the IMDB data</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YB6YP11v2xOL",
        "outputId": "255ed8ee-4824-49a1-d56f-9fac404cc067"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense\n",
        "model = Sequential()\n",
        "model.add(Embedding(10000,8, input_length=maxlen))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
        "model.summary()\n",
        "history = model.fit(x_train, y_train,\n",
        "                    epochs=10,\n",
        "                    batch_size=32,\n",
        "                    validation_split=0.2)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 20, 8)             80000     \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 160)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 161       \n",
            "=================================================================\n",
            "Total params: 80,161\n",
            "Trainable params: 80,161\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "625/625 [==============================] - 5s 3ms/step - loss: 0.6665 - acc: 0.6289 - val_loss: 0.6135 - val_acc: 0.6938\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.5385 - acc: 0.7516 - val_loss: 0.5252 - val_acc: 0.7322\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.4601 - acc: 0.7882 - val_loss: 0.5013 - val_acc: 0.7472\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.4210 - acc: 0.8090 - val_loss: 0.4945 - val_acc: 0.7532\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.3934 - acc: 0.8255 - val_loss: 0.4963 - val_acc: 0.7520\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.3707 - acc: 0.8364 - val_loss: 0.5013 - val_acc: 0.7498\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.3503 - acc: 0.8480 - val_loss: 0.5081 - val_acc: 0.7472\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.3315 - acc: 0.8587 - val_loss: 0.5161 - val_acc: 0.7482\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.3137 - acc: 0.8680 - val_loss: 0.5239 - val_acc: 0.7470\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.2969 - acc: 0.8773 - val_loss: 0.5347 - val_acc: 0.7454\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qR4IXvpu3Owd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}